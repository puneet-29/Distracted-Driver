{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-21T14:02:33.046740Z","iopub.execute_input":"2022-08-21T14:02:33.047215Z","iopub.status.idle":"2022-08-21T14:02:33.069208Z","shell.execute_reply.started":"2022-08-21T14:02:33.047124Z","shell.execute_reply":"2022-08-21T14:02:33.067995Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"## Importing necessary \n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport tensorflow as tf\nimport pathlib\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:58:17.786528Z","iopub.execute_input":"2022-08-21T13:58:17.793470Z","iopub.status.idle":"2022-08-21T13:58:25.415610Z","shell.execute_reply.started":"2022-08-21T13:58:17.789460Z","shell.execute_reply":"2022-08-21T13:58:25.414048Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"## defining the path of our folder containing 10 folders with images corresponding to each category\n\ndata_dir1 = '../input/state-farm-distracted-driver-detection/imgs/train'\ndata_dir = pathlib.Path(data_dir1)\n\n## image count\n\nimage_count = len(list(data_dir.glob('*/*.jpg')))\nprint(image_count)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:58:25.423076Z","iopub.execute_input":"2022-08-21T13:58:25.426844Z","iopub.status.idle":"2022-08-21T13:58:29.991438Z","shell.execute_reply.started":"2022-08-21T13:58:25.426785Z","shell.execute_reply":"2022-08-21T13:58:29.987644Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing\n","metadata":{}},{"cell_type":"code","source":"\n## defining batch size,size of image and dividing data into train and validation data with 20 % validation dataset\n\nbatch_size = 64\nimg_width = 256\nimg_height = 256\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  shuffle=True,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\nval_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  shuffle=True,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\nclass_names = train_ds.class_names\nprint(class_names)\n\n## defining class names \ntrain_ds.class_names = ['safe_drive', 'text_r', 'phone_r', 'text_l', 'phone_l', 'radio', 'drink', 'reach_bhd', 'hair_mkup', 'talk_passenger']\nval_ds.class_names = ['safe_drive', 'text_r', 'phone_r', 'text_l', 'phone_l', 'radio', 'drink', 'reach_bhd', 'hair_mkup', 'talk_passenger']\nclass_names = train_ds.class_names\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:58:29.999551Z","iopub.execute_input":"2022-08-21T13:58:30.002681Z","iopub.status.idle":"2022-08-21T13:59:03.303830Z","shell.execute_reply.started":"2022-08-21T13:58:30.002633Z","shell.execute_reply":"2022-08-21T13:59:03.302403Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"## printing the images for different categories\n\n\nplt.figure(figsize=(25, 25))\nfor images, labels in train_ds.take(3):\n    \n    for i in range(9):\n        \n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")\n\nfor image_batch, labels_batch in train_ds:\n  \n    print(image_batch.shape)\n    print(labels_batch.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:59:03.306084Z","iopub.execute_input":"2022-08-21T13:59:03.306995Z","iopub.status.idle":"2022-08-21T13:59:12.223262Z","shell.execute_reply.started":"2022-08-21T13:59:03.306954Z","shell.execute_reply":"2022-08-21T13:59:12.221368Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Image Augmentation\n","metadata":{}},{"cell_type":"code","source":"\n## image Augmentation which rotates,zooms,flips images to improve the accuracy of model\n\nimg_augmentation = Sequential(\n    [\n        layers.RandomTranslation(height_factor=0.1, width_factor=(0,0.1), input_shape=(img_height, img_width, 3)),\n        layers.RandomFlip(\"horizontal\"),\n        layers.RandomRotation(factor=0.1),\n        layers.RandomZoom(-0.2, 0.1),\n        layers.RandomContrast(factor=(0.2,0)),\n    ],\n    name=\"img_augmentation\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:59:12.230252Z","iopub.execute_input":"2022-08-21T13:59:12.230648Z","iopub.status.idle":"2022-08-21T13:59:12.544721Z","shell.execute_reply.started":"2022-08-21T13:59:12.230611Z","shell.execute_reply":"2022-08-21T13:59:12.543365Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# An image after augmentation\nplt.figure(figsize=(25, 25))\nfor image, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        aug_img = img_augmentation(tf.expand_dims(image[0], axis=0))\n        plt.imshow(aug_img[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:59:12.546601Z","iopub.execute_input":"2022-08-21T13:59:12.547347Z","iopub.status.idle":"2022-08-21T13:59:16.317024Z","shell.execute_reply.started":"2022-08-21T13:59:12.547282Z","shell.execute_reply":"2022-08-21T13:59:16.314599Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Defining custom CNN model","metadata":{}},{"cell_type":"code","source":"\n\n## self defined Cnn model \n\nnum_classes = len(class_names)\n\nmodel = Sequential([\n\n    img_augmentation,\n    layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),  ## Rescaling pixel value \n    \n    ## Adding CNN Layers \n    \n    layers.Conv2D(16, 3, padding='same'),\n\n    layers.Activation('relu'),\n    layers.MaxPooling2D(),\n    \n    layers.Conv2D(32, 3, padding='same'),\n\n    layers.Activation('relu'),\n    layers.MaxPooling2D(),\n    \n    layers.Conv2D(64, 3, padding='same'),\n\n    layers.Activation('relu'),\n    layers.MaxPooling2D(),\n    \n    ## Adding our main layers(Dense and output layer)\n    \n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(num_classes, activation='softmax') ## Output layer\n])\noptimizer = tf.keras.optimizers.Adam()\nmodel.compile(optimizer=optimizer,\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=['sparse_categorical_accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:58:45.921511Z","iopub.execute_input":"2022-08-21T12:58:45.921918Z","iopub.status.idle":"2022-08-21T12:58:46.190995Z","shell.execute_reply.started":"2022-08-21T12:58:45.921884Z","shell.execute_reply":"2022-08-21T12:58:46.189923Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"## Fitting our data to the model\nepochs=10  ## Only 10 epochs due to low computational power\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:58:49.706323Z","iopub.execute_input":"2022-08-21T12:58:49.706709Z","iopub.status.idle":"2022-08-21T13:11:16.747101Z","shell.execute_reply.started":"2022-08-21T12:58:49.706660Z","shell.execute_reply":"2022-08-21T13:11:16.746024Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x=val_ds)  ## An accuracy of 81 % for validation data","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:11:20.151530Z","iopub.execute_input":"2022-08-21T13:11:20.152809Z","iopub.status.idle":"2022-08-21T13:11:31.634744Z","shell.execute_reply.started":"2022-08-21T13:11:20.152768Z","shell.execute_reply":"2022-08-21T13:11:31.633614Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Using Transfer Learning with MobileNetV2 model as base model\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2  ## importing MobileNetV2 model","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:31:02.709705Z","iopub.execute_input":"2022-08-21T12:31:02.710398Z","iopub.status.idle":"2022-08-21T12:31:02.715243Z","shell.execute_reply.started":"2022-08-21T12:31:02.710365Z","shell.execute_reply":"2022-08-21T12:31:02.714234Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"## Defining our model along with MobileNetV2\n\n\nconv_model = MobileNetV2(weights='imagenet',include_top=False,input_shape = (256,256,3))\n\n\n## Making last layer of Mobilent as Non trainable so that we can have our own output layer\n\n\nfor layer in conv_model.layers[:-3]:\n    layer.trainable=False        \n\n\nm_model = Sequential()\nm_model.add(conv_model)\nm_model.add(layers.Flatten())\n\n\n\n\nm_model.add(layers.Dense(256,activation = 'relu'))\n\n\nm_model.add(layers.Dense(128,activation = 'relu'))\n\n\nm_model.add(layers.Dense(10,activation = 'softmax',name = 'output'))\n\n\n\nm_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:58:21.619023Z","iopub.execute_input":"2022-08-21T12:58:21.619517Z","iopub.status.idle":"2022-08-21T12:58:23.307324Z","shell.execute_reply.started":"2022-08-21T12:58:21.619485Z","shell.execute_reply":"2022-08-21T12:58:23.306263Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"m_model.compile(optimizer = optimizers.Adam(learning_rate=.0001) ,\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=['sparse_categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:33:24.356900Z","iopub.execute_input":"2022-08-21T12:33:24.357555Z","iopub.status.idle":"2022-08-21T12:33:24.371672Z","shell.execute_reply.started":"2022-08-21T12:33:24.357520Z","shell.execute_reply":"2022-08-21T12:33:24.370728Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"## Running our model\nepochs=10\nhistory = m_model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:42:15.786173Z","iopub.execute_input":"2022-08-21T12:42:15.786542Z","iopub.status.idle":"2022-08-21T12:54:43.683124Z","shell.execute_reply.started":"2022-08-21T12:42:15.786511Z","shell.execute_reply":"2022-08-21T12:54:43.682119Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Final Accuracy\n","metadata":{}},{"cell_type":"code","source":"m_model.evaluate(x=val_ds)  ## Achieving a high accuracy of 96.7 % for validation data","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:56:24.547040Z","iopub.execute_input":"2022-08-21T12:56:24.547854Z","iopub.status.idle":"2022-08-21T12:56:45.045593Z","shell.execute_reply.started":"2022-08-21T12:56:24.547808Z","shell.execute_reply":"2022-08-21T12:56:45.044451Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}